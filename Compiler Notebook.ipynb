{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPILER USAGE NOTEBOOK\n",
    "### Input file exemple\n",
    "Please enter in between the quotes of variable string the wanted program\n",
    "All this code will do is take that wanted string and save it in a given file named \"newfile.txt\"\n",
    "Change the filename as you wish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"\"\"\n",
    "#TIMESCALE\n",
    "horizon: 3\n",
    "step: 1\n",
    "\n",
    "#NODE ABC\n",
    "#PARAMETERS\n",
    "c = 10 +10.01\n",
    "v = (5)**c\n",
    "#VARIABLES \n",
    "internal : a\n",
    "output : b\n",
    "#CONSTRAINTS\n",
    "a[0]=1\n",
    "a[t+1] = 3*a[0]\n",
    "b[t*c+1] = 3*a\n",
    "b[t]-(3*b[t+1] + (-a[t]))=-2*b[t]+1 \n",
    "b-(3*b[t+1] + (-a))=-2*b+1 \n",
    "\n",
    "#OBJECTIVE\n",
    "min : a\n",
    "\n",
    "#LINKS\n",
    "A = B,C\n",
    "A.pay = B.day\"\"\"\n",
    "f = open(\"newfile.txt\", \"w\")\n",
    "f.write(string)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexer\n",
    "The lexer takes as input a file seen as a stream of characters and converts into a stream of tokens\n",
    "The tokens can be seen below with each token being the token name, Value, Line at which it was declared and the total number of characters read before the first character of this token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LexToken(TIME,'#TIMESCALE',40,1)\n",
      "LexToken(HORIZON,'horizon',41,12)\n",
      "LexToken(COLON,':',41,19)\n",
      "LexToken(INT,3,41,21)\n",
      "LexToken(STEP,'step',42,23)\n",
      "LexToken(COLON,':',42,27)\n",
      "LexToken(INT,1,42,29)\n",
      "LexToken(NODE,'#NODE',44,32)\n",
      "LexToken(NAME,'ABC',44,38)\n",
      "LexToken(PARAM,'#PARAMETERS',45,42)\n",
      "LexToken(ID,'c',46,54)\n",
      "LexToken(EQUAL,'=',46,56)\n",
      "LexToken(INT,10,46,58)\n",
      "LexToken(PLUS,'+',46,61)\n",
      "LexToken(FLOAT,10.01,46,62)\n",
      "LexToken(ID,'v',47,68)\n",
      "LexToken(EQUAL,'=',47,70)\n",
      "LexToken(LPAR,'(',47,72)\n",
      "LexToken(INT,5,47,73)\n",
      "LexToken(RPAR,')',47,74)\n",
      "LexToken(POW,'**',47,75)\n",
      "LexToken(ID,'c',47,77)\n",
      "LexToken(VAR,'#VARIABLES',48,79)\n",
      "LexToken(INTERNAL,'internal',49,91)\n",
      "LexToken(COLON,':',49,100)\n",
      "LexToken(ID,'a',49,102)\n",
      "LexToken(OUTPUT,'output',50,104)\n",
      "LexToken(COLON,':',50,111)\n",
      "LexToken(ID,'b',50,113)\n",
      "LexToken(CONS,'#CONSTRAINTS',51,115)\n",
      "LexToken(ID,'a',52,128)\n",
      "LexToken(LBRAC,'[',52,129)\n",
      "LexToken(INT,0,52,130)\n",
      "LexToken(RBRAC,']',52,131)\n",
      "LexToken(EQUAL,'=',52,132)\n",
      "LexToken(INT,1,52,133)\n",
      "LexToken(ID,'a',53,135)\n",
      "LexToken(LBRAC,'[',53,136)\n",
      "LexToken(ID,'t',53,137)\n",
      "LexToken(PLUS,'+',53,138)\n",
      "LexToken(INT,1,53,139)\n",
      "LexToken(RBRAC,']',53,140)\n",
      "LexToken(EQUAL,'=',53,142)\n",
      "LexToken(INT,3,53,144)\n",
      "LexToken(TIMES,'*',53,145)\n",
      "LexToken(ID,'a',53,146)\n",
      "LexToken(LBRAC,'[',53,147)\n",
      "LexToken(INT,0,53,148)\n",
      "LexToken(RBRAC,']',53,149)\n",
      "LexToken(ID,'b',54,151)\n",
      "LexToken(LBRAC,'[',54,152)\n",
      "LexToken(ID,'t',54,153)\n",
      "LexToken(TIMES,'*',54,154)\n",
      "LexToken(ID,'c',54,155)\n",
      "LexToken(PLUS,'+',54,156)\n",
      "LexToken(INT,1,54,157)\n",
      "LexToken(RBRAC,']',54,158)\n",
      "LexToken(EQUAL,'=',54,160)\n",
      "LexToken(INT,3,54,162)\n",
      "LexToken(TIMES,'*',54,163)\n",
      "LexToken(ID,'a',54,164)\n",
      "LexToken(ID,'b',55,166)\n",
      "LexToken(LBRAC,'[',55,167)\n",
      "LexToken(ID,'t',55,168)\n",
      "LexToken(RBRAC,']',55,169)\n",
      "LexToken(MINUS,'-',55,170)\n",
      "LexToken(LPAR,'(',55,171)\n",
      "LexToken(INT,3,55,172)\n",
      "LexToken(TIMES,'*',55,173)\n",
      "LexToken(ID,'b',55,174)\n",
      "LexToken(LBRAC,'[',55,175)\n",
      "LexToken(ID,'t',55,176)\n",
      "LexToken(PLUS,'+',55,177)\n",
      "LexToken(INT,1,55,178)\n",
      "LexToken(RBRAC,']',55,179)\n",
      "LexToken(PLUS,'+',55,181)\n",
      "LexToken(LPAR,'(',55,183)\n",
      "LexToken(MINUS,'-',55,184)\n",
      "LexToken(ID,'a',55,185)\n",
      "LexToken(LBRAC,'[',55,186)\n",
      "LexToken(ID,'t',55,187)\n",
      "LexToken(RBRAC,']',55,188)\n",
      "LexToken(RPAR,')',55,189)\n",
      "LexToken(RPAR,')',55,190)\n",
      "LexToken(EQUAL,'=',55,191)\n",
      "LexToken(MINUS,'-',55,192)\n",
      "LexToken(INT,2,55,193)\n",
      "LexToken(TIMES,'*',55,194)\n",
      "LexToken(ID,'b',55,195)\n",
      "LexToken(LBRAC,'[',55,196)\n",
      "LexToken(ID,'t',55,197)\n",
      "LexToken(RBRAC,']',55,198)\n",
      "LexToken(PLUS,'+',55,199)\n",
      "LexToken(INT,1,55,200)\n",
      "LexToken(ID,'b',56,203)\n",
      "LexToken(MINUS,'-',56,204)\n",
      "LexToken(LPAR,'(',56,205)\n",
      "LexToken(INT,3,56,206)\n",
      "LexToken(TIMES,'*',56,207)\n",
      "LexToken(ID,'b',56,208)\n",
      "LexToken(LBRAC,'[',56,209)\n",
      "LexToken(ID,'t',56,210)\n",
      "LexToken(PLUS,'+',56,211)\n",
      "LexToken(INT,1,56,212)\n",
      "LexToken(RBRAC,']',56,213)\n",
      "LexToken(PLUS,'+',56,215)\n",
      "LexToken(LPAR,'(',56,217)\n",
      "LexToken(MINUS,'-',56,218)\n",
      "LexToken(ID,'a',56,219)\n",
      "LexToken(RPAR,')',56,220)\n",
      "LexToken(RPAR,')',56,221)\n",
      "LexToken(EQUAL,'=',56,222)\n",
      "LexToken(MINUS,'-',56,223)\n",
      "LexToken(INT,2,56,224)\n",
      "LexToken(TIMES,'*',56,225)\n",
      "LexToken(ID,'b',56,226)\n",
      "LexToken(PLUS,'+',56,227)\n",
      "LexToken(INT,1,56,228)\n",
      "LexToken(OBJ,'#OBJECTIVE',58,232)\n",
      "LexToken(MIN,'min',59,243)\n",
      "LexToken(COLON,':',59,247)\n",
      "LexToken(ID,'a',59,249)\n",
      "LexToken(NODE,'#NODE',61,252)\n",
      "LexToken(NAME,'ABCD',61,258)\n",
      "LexToken(PARAM,'#PARAMETERS',62,263)\n",
      "LexToken(ID,'c',63,275)\n",
      "LexToken(EQUAL,'=',63,277)\n",
      "LexToken(INT,10,63,279)\n",
      "LexToken(PLUS,'+',63,282)\n",
      "LexToken(FLOAT,10.01,63,283)\n",
      "LexToken(ID,'v',64,289)\n",
      "LexToken(EQUAL,'=',64,291)\n",
      "LexToken(LPAR,'(',64,293)\n",
      "LexToken(INT,5,64,294)\n",
      "LexToken(RPAR,')',64,295)\n",
      "LexToken(POW,'**',64,296)\n",
      "LexToken(ID,'c',64,298)\n",
      "LexToken(VAR,'#VARIABLES',65,300)\n",
      "LexToken(INTERNAL,'internal',66,312)\n",
      "LexToken(COLON,':',66,321)\n",
      "LexToken(ID,'a',66,323)\n",
      "LexToken(OUTPUT,'output',67,325)\n",
      "LexToken(COLON,':',67,332)\n",
      "LexToken(ID,'b',67,334)\n",
      "LexToken(CONS,'#CONSTRAINTS',68,336)\n",
      "LexToken(ID,'a',69,349)\n",
      "LexToken(LBRAC,'[',69,350)\n",
      "LexToken(INT,0,69,351)\n",
      "LexToken(RBRAC,']',69,352)\n",
      "LexToken(EQUAL,'=',69,353)\n",
      "LexToken(INT,1,69,354)\n",
      "LexToken(ID,'a',70,356)\n",
      "LexToken(LBRAC,'[',70,357)\n",
      "LexToken(ID,'t',70,358)\n",
      "LexToken(PLUS,'+',70,359)\n",
      "LexToken(INT,1,70,360)\n",
      "LexToken(RBRAC,']',70,361)\n",
      "LexToken(EQUAL,'=',70,363)\n",
      "LexToken(INT,3,70,365)\n",
      "LexToken(TIMES,'*',70,366)\n",
      "LexToken(ID,'a',70,367)\n",
      "LexToken(LBRAC,'[',70,368)\n",
      "LexToken(INT,0,70,369)\n",
      "LexToken(RBRAC,']',70,370)\n",
      "LexToken(ID,'b',71,372)\n",
      "LexToken(LBRAC,'[',71,373)\n",
      "LexToken(ID,'t',71,374)\n",
      "LexToken(TIMES,'*',71,375)\n",
      "LexToken(ID,'c',71,376)\n",
      "LexToken(PLUS,'+',71,377)\n",
      "LexToken(INT,1,71,378)\n",
      "LexToken(RBRAC,']',71,379)\n",
      "LexToken(EQUAL,'=',71,381)\n",
      "LexToken(INT,3,71,383)\n",
      "LexToken(TIMES,'*',71,384)\n",
      "LexToken(ID,'a',71,385)\n",
      "LexToken(ID,'b',72,387)\n",
      "LexToken(LBRAC,'[',72,388)\n",
      "LexToken(ID,'t',72,389)\n",
      "LexToken(RBRAC,']',72,390)\n",
      "LexToken(MINUS,'-',72,391)\n",
      "LexToken(LPAR,'(',72,392)\n",
      "LexToken(INT,3,72,393)\n",
      "LexToken(TIMES,'*',72,394)\n",
      "LexToken(ID,'b',72,395)\n",
      "LexToken(LBRAC,'[',72,396)\n",
      "LexToken(ID,'t',72,397)\n",
      "LexToken(PLUS,'+',72,398)\n",
      "LexToken(INT,1,72,399)\n",
      "LexToken(RBRAC,']',72,400)\n",
      "LexToken(PLUS,'+',72,402)\n",
      "LexToken(LPAR,'(',72,404)\n",
      "LexToken(MINUS,'-',72,405)\n",
      "LexToken(ID,'a',72,406)\n",
      "LexToken(LBRAC,'[',72,407)\n",
      "LexToken(ID,'t',72,408)\n",
      "LexToken(RBRAC,']',72,409)\n",
      "LexToken(RPAR,')',72,410)\n",
      "LexToken(RPAR,')',72,411)\n",
      "LexToken(EQUAL,'=',72,412)\n",
      "LexToken(MINUS,'-',72,413)\n",
      "LexToken(INT,2,72,414)\n",
      "LexToken(TIMES,'*',72,415)\n",
      "LexToken(ID,'b',72,416)\n",
      "LexToken(LBRAC,'[',72,417)\n",
      "LexToken(ID,'t',72,418)\n",
      "LexToken(RBRAC,']',72,419)\n",
      "LexToken(PLUS,'+',72,420)\n",
      "LexToken(INT,1,72,421)\n",
      "LexToken(ID,'b',73,424)\n",
      "LexToken(MINUS,'-',73,425)\n",
      "LexToken(LPAR,'(',73,426)\n",
      "LexToken(INT,3,73,427)\n",
      "LexToken(TIMES,'*',73,428)\n",
      "LexToken(ID,'b',73,429)\n",
      "LexToken(LBRAC,'[',73,430)\n",
      "LexToken(ID,'t',73,431)\n",
      "LexToken(PLUS,'+',73,432)\n",
      "LexToken(INT,1,73,433)\n",
      "LexToken(RBRAC,']',73,434)\n",
      "LexToken(PLUS,'+',73,436)\n",
      "LexToken(LPAR,'(',73,438)\n",
      "LexToken(MINUS,'-',73,439)\n",
      "LexToken(ID,'a',73,440)\n",
      "LexToken(RPAR,')',73,441)\n",
      "LexToken(RPAR,')',73,442)\n",
      "LexToken(EQUAL,'=',73,443)\n",
      "LexToken(MINUS,'-',73,444)\n",
      "LexToken(INT,2,73,445)\n",
      "LexToken(TIMES,'*',73,446)\n",
      "LexToken(ID,'b',73,447)\n",
      "LexToken(PLUS,'+',73,448)\n",
      "LexToken(INT,1,73,449)\n",
      "LexToken(LINKS,'#LINKS',75,453)\n",
      "LexToken(NAME,'A',76,460)\n",
      "LexToken(EQUAL,'=',76,462)\n",
      "LexToken(NAME,'B',76,464)\n",
      "LexToken(COMMA,',',76,465)\n",
      "LexToken(NAME,'C',76,466)\n",
      "LexToken(NAME,'A',77,468)\n",
      "LexToken(DOT,'.',77,469)\n",
      "LexToken(ID,'pay',77,470)\n",
      "LexToken(EQUAL,'=',77,474)\n",
      "LexToken(NAME,'B',77,476)\n",
      "LexToken(DOT,'.',77,477)\n",
      "LexToken(ID,'day',77,478)\n"
     ]
    }
   ],
   "source": [
    "from lexer import tokenize_file\n",
    "\n",
    "tokenize_file(\"newfile.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parser\n",
    "#### Classes\n",
    "Takes as input the token stream and converts it to various a program class containing all the necessary information about the input file. \n",
    "\n",
    "The Program file is made up of : \n",
    "- A list of node objects\n",
    "- A list of Links\n",
    "- Information about time contained in timeclass\n",
    "\n",
    "The Node object is made up of : \n",
    "- A name\n",
    "- A list of Parameter objects\n",
    "- A list of Variables \n",
    "- A list of Constraints \n",
    "- A list of Objective functions\n",
    "\n",
    "A Parameter object contains:\n",
    "- A name (parameter name)\n",
    "- An expression (the rhs of the equality)\n",
    "\n",
    "A Variable contains : \n",
    "- A name (Variable name)\n",
    "- A parameter Type (Internal - Input - Output)\n",
    "\n",
    "A constraint contains :\n",
    "- A rhs expression \n",
    "- A sign (between \"=\",\"<=\",\"<\",\">=\",\">\")\n",
    "- A lhs expression\n",
    "\n",
    "An objective is made up of:\n",
    "- A objective function between min or max\n",
    "- An expression\n",
    "\n",
    "An expression object contains : \n",
    "- A type between : \n",
    "    - 'literal' if it is a identifier, a float or an integer\n",
    "    - '*' '/' '+' '-' if it is the according operation between two expression\n",
    "    - 'u-' if it is a unary minus\n",
    "- A list of child expressions\n",
    "- A name containing the according identifier, float or integer if its type is literal\n",
    "\n",
    "An expression object is build up as a tree of expression as follows, it starts from the bottom and goes upward:\n",
    "- An integer, float or identifier is turned into a 'literal' type expression with the expression name containing the corresponding value\n",
    "- If a unary minus is applied over an expression: \n",
    "    - A new expression 'u-' is created with only one child\n",
    "- If a sum,division,soustraction,multiplication is applied between two expressions:\n",
    "    - A new expression with the correspond type defined as the sign of the operation and two child expression\n",
    "- If an expression is contained between parenthesis, simply the parenthesis are ignored\n",
    "\n",
    "The priority of operations is given by a predefined precedence rule which corresponds to the usual mathematical precedence\n",
    "\n",
    "#### Code\n",
    "In the following code, the 'newfile.txt' file goes through the lexer and the corresponding stream is given to the parser which following a given grammar creates a full Program object. The full program object is printed. A more comprehensive way of seeing the different components of an object from the program class can be obtained by using the function 'to_string()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ [ABCD , [ [c , [+ , [ 10 10.01]]] [v , [** , [ 5 c]]]] , [ [a , internal] [b , output]] , [ [= , a[0] , 1] [= , a[[+ , [ t 1]]] , [* , [ 3 a[0]]]] [= , b[[+ , [ [* , [ t c]] 1]]] , [* , [ 3 a]]] [= , [- , [ b[t] [+ , [ [* , [ 3 b[[+ , [ t 1]]]]] [u- , [ a[t]]]]]]] , [+ , [ [* , [ [u- , [ 2]] b[t]]] 1]]] [= , [- , [ b [+ , [ [* , [ 3 b[[+ , [ t 1]]]]] [u- , [ a]]]]]] , [+ , [ [* , [ [u- , [ 2]] b]] 1]]]] , []] [ABC , [ [c , [+ , [ 10 10.01]]] [v , [** , [ 5 c]]]] , [ [a , internal] [b , output]] , [ [= , a[0] , 1] [= , a[[+ , [ t 1]]] , [* , [ 3 a[0]]]] [= , b[[+ , [ [* , [ t c]] 1]]] , [* , [ 3 a]]] [= , [- , [ b[t] [+ , [ [* , [ 3 b[[+ , [ t 1]]]]] [u- , [ a[t]]]]]]] , [+ , [ [* , [ [u- , [ 2]] b[t]]] 1]]] [= , [- , [ b [+ , [ [* , [ 3 b[[+ , [ t 1]]]]] [u- , [ a]]]]]] , [+ , [ [* , [ [u- , [ 2]] b]] 1]]]] , [ [min,a]]]] , time: 3 step: 1 , [ [A , [ B C]] [A.pay , [ B.day]]]]\n",
      "\n",
      "\n",
      "Full program\n",
      "Time horizon : 3\n",
      "Time step : 1\n",
      "All the defined nodes : \n",
      "\tName : ABCD\n",
      "\t\tParameters : [ [c , [+ , [ 10 10.01]]] [v , [** , [ 5 c]]]]\n",
      "\t\tVariables : [ [a , internal] [b , output]]\n",
      "\t\tConstraints : [ [= , a[0] , 1] [= , a[[+ , [ t 1]]] , [* , [ 3 a[0]]]] [= , b[[+ , [ [* , [ t c]] 1]]] , [* , [ 3 a]]] [= , [- , [ b[t] [+ , [ [* , [ 3 b[[+ , [ t 1]]]]] [u- , [ a[t]]]]]]] , [+ , [ [* , [ [u- , [ 2]] b[t]]] 1]]] [= , [- , [ b [+ , [ [* , [ 3 b[[+ , [ t 1]]]]] [u- , [ a]]]]]] , [+ , [ [* , [ [u- , [ 2]] b]] 1]]]]\n",
      "\t\tObjectives : []\n",
      "\tName : ABC\n",
      "\t\tParameters : [ [c , [+ , [ 10 10.01]]] [v , [** , [ 5 c]]]]\n",
      "\t\tVariables : [ [a , internal] [b , output]]\n",
      "\t\tConstraints : [ [= , a[0] , 1] [= , a[[+ , [ t 1]]] , [* , [ 3 a[0]]]] [= , b[[+ , [ [* , [ t c]] 1]]] , [* , [ 3 a]]] [= , [- , [ b[t] [+ , [ [* , [ 3 b[[+ , [ t 1]]]]] [u- , [ a[t]]]]]]] , [+ , [ [* , [ [u- , [ 2]] b[t]]] 1]]] [= , [- , [ b [+ , [ [* , [ 3 b[[+ , [ t 1]]]]] [u- , [ a]]]]]] , [+ , [ [* , [ [u- , [ 2]] b]] 1]]]]\n",
      "\t\tObjectives : [ [min,a]]\n",
      "\n",
      "Links predefined are : [ [A , [ B C]] [A.pay , [ B.day]]]\n"
     ]
    }
   ],
   "source": [
    "from Myparser import parse_file\n",
    "\n",
    "\n",
    "result = parse_file(\"newfile.txt\")\n",
    "print(result)\n",
    "print(\"\\n\")\n",
    "print(result.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix  acquisition \n",
    "\n",
    "All the previous steps can be called by using main.py.\n",
    "- The --lex option prints all the Tokens stream \n",
    "- The --parse option prints the syntax tree\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a[0] b[0] \n",
      "a[1] b[1] \n",
      "a[2] b[2] \n",
      "\n",
      "CONSTRAINT : 0\n",
      "t : 0\n",
      "1 0 0 \n",
      "0 0 0 \n",
      "t : 1\n",
      "1 0 0 \n",
      "0 0 0 \n",
      "t : 2\n",
      "1 0 0 \n",
      "0 0 0 \n",
      "const : 1\n",
      "CONSTRAINT : 1\n",
      "t : 0\n",
      "-3 1 0 \n",
      "0 0 0 \n",
      "t : 1\n",
      "-3 0 1 \n",
      "0 0 0 \n",
      "t : 2\n",
      "-3 0 0 \n",
      "0 0 0 \n",
      "const : 0\n",
      "CONSTRAINT : 2\n",
      "t : 0\n",
      "-3 0 0 \n",
      "0 1 0 \n",
      "t : 1\n",
      "0 -3 0 \n",
      "0 0 0 \n",
      "t : 2\n",
      "0 0 -3 \n",
      "0 0 0 \n",
      "const : 0\n",
      "CONSTRAINT : 3\n",
      "t : 0\n",
      "1 0 0 \n",
      "3 -3 0 \n",
      "t : 1\n",
      "0 1 0 \n",
      "0 3 -3 \n",
      "t : 2\n",
      "0 0 1 \n",
      "0 0 3 \n",
      "const : 1\n",
      "CONSTRAINT : 4\n",
      "t : 0\n",
      "1 0 0 \n",
      "3 -3 0 \n",
      "t : 1\n",
      "0 1 0 \n",
      "0 3 -3 \n",
      "t : 2\n",
      "0 0 1 \n",
      "0 0 3 \n",
      "const : 1\n",
      "a[0] b[0] \n",
      "a[1] b[1] \n",
      "a[2] b[2] \n",
      "\n",
      "CONSTRAINT : 0\n",
      "t : 0\n",
      "1 0 0 \n",
      "0 0 0 \n",
      "t : 1\n",
      "1 0 0 \n",
      "0 0 0 \n",
      "t : 2\n",
      "1 0 0 \n",
      "0 0 0 \n",
      "const : 1\n",
      "CONSTRAINT : 1\n",
      "t : 0\n",
      "-3 1 0 \n",
      "0 0 0 \n",
      "t : 1\n",
      "-3 0 1 \n",
      "0 0 0 \n",
      "t : 2\n",
      "-3 0 0 \n",
      "0 0 0 \n",
      "const : 0\n",
      "CONSTRAINT : 2\n",
      "t : 0\n",
      "-3 0 0 \n",
      "0 1 0 \n",
      "t : 1\n",
      "0 -3 0 \n",
      "0 0 0 \n",
      "t : 2\n",
      "0 0 -3 \n",
      "0 0 0 \n",
      "const : 0\n",
      "CONSTRAINT : 3\n",
      "t : 0\n",
      "1 0 0 \n",
      "3 -3 0 \n",
      "t : 1\n",
      "0 1 0 \n",
      "0 3 -3 \n",
      "t : 2\n",
      "0 0 1 \n",
      "0 0 3 \n",
      "const : 1\n",
      "CONSTRAINT : 4\n",
      "t : 0\n",
      "1 0 0 \n",
      "3 -3 0 \n",
      "t : 1\n",
      "0 1 0 \n",
      "0 3 -3 \n",
      "t : 2\n",
      "0 0 1 \n",
      "0 0 3 \n",
      "const : 1\n"
     ]
    }
   ],
   "source": [
    "!python main.py newfile.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
